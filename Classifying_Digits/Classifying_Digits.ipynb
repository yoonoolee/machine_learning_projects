{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>Classifying Digits</center>\n",
    "</h1>\n",
    "\n",
    "<h1>\n",
    "<center>Avery Lee</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classification and Regression \n",
    "\n",
    "Let's explore using SVM classification for the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, cache=True)\n",
    "mnist.target = mnist.target.astype(np.int8)\n",
    "X_train = mnist[\"data\"][:60000]\n",
    "X_test  = mnist[\"data\"][60000:]\n",
    "y_train = mnist[\"target\"][:60000]\n",
    "y_test  = mnist[\"target\"][60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "N = 2000\n",
    "split_obj = StratifiedShuffleSplit(n_splits=1,\n",
    "                               test_size=N/60000, random_state=42)\n",
    "for other_idx, subsample_idx in split_obj.split(X_train, y_train):\n",
    "    X = X_train[subsample_idx]\n",
    "    y = y_train[subsample_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the linear SVM classifier (`LinearSVC`) with `max_iter=50000`. For this model, optimize the hyperparameter $C$ using 3-fold CV over the values $10^{-k}$, $k=0,1,\\dots,9$, where the performance measure is accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best C is 1e-07 and the accuracy is 0.862497."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator, accuracy: LinearSVC(C=1e-07, max_iter=50000, random_state=42), 0.8624974299636969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm_clf = LinearSVC(random_state=42, max_iter=50000)\n",
    "param_distributions = [{'C':[10**(-k) for k in range(10)]}]\n",
    "rnd_search_cv = GridSearchCV(svm_clf, param_distributions, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "rnd_search_cv.fit(X, y)\n",
    "rnd_best_estim = rnd_search_cv.best_estimator_\n",
    "rnd_accuracy = rnd_search_cv.best_score_\n",
    "print(f'best estimator, accuracy: {rnd_best_estim}, {rnd_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try fitting a SVM with a Gaussian RBF kernel and `max_iter=50000`. For this model, optimize the hyperparameters $C$ over the distrbution `uniform(1,10)` and $\\gamma$ over the distribution `reciprocal(0.001, 0.1)` with 10 random samples. Again, use 3-fold CV and the performance measure is accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameters are C=4.745401188473625 and gamma=0.07969454818643928, and the accuracy is 0.11250005627."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator, accuracy: SVC(C=4.745401188473625, gamma=0.07969454818643928, max_iter=50000,\n",
      "    random_state=42), 0.11250005627816723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rbfc_param_distributions = {\"C\": uniform(1, 10), \"gamma\": reciprocal(0.001, 0.1)}\n",
    "rbfc_svm_clf = SVC(kernel='rbf', max_iter=50000, random_state=42)\n",
    "rbfc_rnd_search_cv = RandomizedSearchCV(rbfc_svm_clf, \n",
    "                                        rbfc_param_distributions, \n",
    "                                        n_iter=10, \n",
    "                                        cv=3,\n",
    "                                        scoring='accuracy',\n",
    "                                        n_jobs=-1,\n",
    "                                        random_state=42)\n",
    "rbfc_rnd_search_cv.fit(X, y)\n",
    "rbfc_best_estim = rbfc_rnd_search_cv.best_estimator_\n",
    "rbfc_accuracy = rbfc_rnd_search_cv.best_score_\n",
    "print(f'best estimator, accuracy: {rbfc_best_estim}, {rbfc_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we can see that the better model is the LinearSVC. The accuracy for the test set is 0.8873."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8873"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# (a) had better accuracy than (b)\n",
    "y_pred1 = rnd_best_estim.predict(X_test)\n",
    "better_accuracy = accuracy_score(y_test, y_pred1)\n",
    "better_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifiers \n",
    "\n",
    "Now let's explore voting classifiers as well. To save computational time, split it into a smaller training set (the first 5000 observations) and a validation set (the next 1000 observations) as given by the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "M = 6000\n",
    "X_train = mnist[\"data\"][:N]\n",
    "X_val  = mnist[\"data\"][N:M]\n",
    "y_train = mnist[\"target\"][:N]\n",
    "y_val = mnist[\"target\"][N:M]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the following classifiers on the training set:\n",
    "\n",
    "(i) a random forest classifier with arguments `n_estimators=100, n_jobs=-1, random_state=42`,\n",
    "\n",
    "(ii) an extra-trees classifier with arguments `n_estimators=100, n_jobs=-1, random_state=42`,\n",
    "\n",
    "(iii) an AdaBoost classifier `n_estimators=50, learning_rate=0.2, random_state=42`,\n",
    "\n",
    "(iv) a gradient boosting classifier using the class `GradientBoostingClassifier()` with arguments `max_depth=2, n_estimators=10, learning_rate=0.25, random_state=42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(classifiers):\n",
    "    for clf in classifiers:\n",
    "        clf.fit(X_train, y_train)\n",
    "        clf_y_pred = clf.predict(X_val)\n",
    "        print(clf.__class__.__name__, accuracy_score(y_val, clf_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "# (i)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "\n",
    "# (ii)\n",
    "extra_clf = ExtraTreesClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "\n",
    "# (iii)\n",
    "ada_clf = AdaBoostClassifier(n_estimators=50, learning_rate=0.2, random_state=42)\n",
    "\n",
    "# (iv)\n",
    "gb_clf = GradientBoostingClassifier(max_depth=2, n_estimators=10, learning_rate=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the results below that the ExtraTreesClassifier had the best training accuracy of 0.947."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.939\n",
      "ExtraTreesClassifier 0.947\n",
      "AdaBoostClassifier 0.736\n",
      "GradientBoostingClassifier 0.834\n"
     ]
    }
   ],
   "source": [
    "# fit, predict, accuracy \n",
    "print_accuracy([rf_clf, extra_clf, ada_clf, gb_clf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a hard-voting and a soft-voting ensemble classifier based on the models using SVM. Evaluate each voting classifier on the validation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hard voting and soft voting classifiers got 0.923 and 0.926 accuracies respectively. The performance of the ensemble model is similar to the individual models since the accuracies for both the hard and soft voting classifiers are in the middle (higher than adaboost and gradient boosting but lower than random forest and extratrees) of the accuracies for the four models. This makes sense as the voting classifiers are taking votes from all 4 of the classifier types, so it would work better than some but also worse than other models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=42)),\n",
       "                             ('extra',\n",
       "                              ExtraTreesClassifier(n_jobs=-1, random_state=42)),\n",
       "                             ('ada',\n",
       "                              AdaBoostClassifier(learning_rate=0.2,\n",
       "                                                 random_state=42)),\n",
       "                             ('gb',\n",
       "                              GradientBoostingClassifier(learning_rate=0.25,\n",
       "                                                         max_depth=2,\n",
       "                                                         n_estimators=10,\n",
       "                                                         random_state=42))],\n",
       "                 voting='soft')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "hard_voting_clf = VotingClassifier(estimators=[('rf', rf_clf), \n",
    "                                               ('extra', extra_clf), \n",
    "                                               ('ada', ada_clf), \n",
    "                                               ('gb', gb_clf)], \n",
    "                                   voting='hard')\n",
    "\n",
    "soft_voting_clf = VotingClassifier(estimators=[('rf', rf_clf), \n",
    "                                               ('extra', extra_clf), \n",
    "                                               ('ada', ada_clf), \n",
    "                                               ('gb', gb_clf)], \n",
    "                                   voting='soft')\n",
    "\n",
    "# fit, predict, accuracy \n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "soft_voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.923\n",
      "VotingClassifier 0.926\n"
     ]
    }
   ],
   "source": [
    "print_accuracy([hard_voting_clf, soft_voting_clf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking \n",
    "\n",
    "For each of the four voting classifiers, let's make 5000 clean predictions on the training set with 3-fold cross validation using `sklearn.model_selection.cross_val_predict()`. You should end up with four predictions per observation. Next, apply one-hot encoding to `pred` since these predictions are class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# cross validation predict\n",
    "rf_y_train_pred = cross_val_predict(rf_clf, X_train, y_train, cv=3, n_jobs=-1)\n",
    "extra_y_train_pred = cross_val_predict(extra_clf, X_train, y_train, cv=3, n_jobs=-1)\n",
    "ada_y_train_pred = cross_val_predict(ada_clf, X_train, y_train, cv=3, n_jobs=-1)\n",
    "gb_y_train_pred = cross_val_predict(gb_clf, X_train, y_train, cv=3, n_jobs=-1)\n",
    "\n",
    "train_preds = pd.DataFrame({'rf':rf_y_train_pred, \n",
    "                            'extra':extra_y_train_pred, \n",
    "                            'ada boost':ada_y_train_pred, \n",
    "                            'gradient boost':gb_y_train_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>extra</th>\n",
       "      <th>ada boost</th>\n",
       "      <th>gradient boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rf  extra  ada boost  gradient boost\n",
       "0   5      5          3               3\n",
       "1   0      0          5               0\n",
       "2   4      4          4               4\n",
       "3   1      1          1               1\n",
       "4   9      9          9               9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_preds[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...   30   31   32  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1     1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0   \n",
       "2     0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "4995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4996  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4997  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "4998  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
       "4999  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "\n",
       "       33   34   35   36   37   38   39  \n",
       "0     1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "4995  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "4996  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5000 rows x 40 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# one hot encoding\n",
    "ohenc = OneHotEncoder()\n",
    "ohencX_train = pd.DataFrame(ohenc.fit_transform(train_preds).toarray())\n",
    "ohencX_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the predictions as features and the actual label of the observations as the target. Train a random forest classifier on the training set with the parameters `n_estimators=100, random_state=42`. This classifier is a blender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=42)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_blender = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_blender.fit(ohencX_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the predictions of the blender on the validation set by feeding predictions on the validation set from the four voting classifiers into the blender trained. These are called stacking predictions. Report the accuracy of your stacking predictions on the validation set and compare to the original predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stacking predictor had an accuracy of 0.947, which is better than both the initial hard and soft voting classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_val_pred = rf_clf.predict(X_val)\n",
    "extra_val_pred = extra_clf.predict(X_val)\n",
    "ada_val_pred = ada_clf.predict(X_val)\n",
    "gb_val_pred = gb_clf.predict(X_val)\n",
    "\n",
    "val_preds = pd.DataFrame({'rf':rf_val_pred, \n",
    "                          'extra':extra_val_pred, \n",
    "                          'ada boost':ada_val_pred, \n",
    "                          'gradient boost':gb_val_pred})\n",
    "                          \n",
    "ohenc = OneHotEncoder()\n",
    "ohencX_val = pd.DataFrame(ohenc.fit_transform(val_preds).toarray())\n",
    "blender_val_preds = rf_blender.predict(ohencX_val)\n",
    "blender_val_accuracy = accuracy_score(y_val, blender_val_preds)\n",
    "blender_val_accuracy"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
